{"schema_version":"1.7.3","id":"UBUNTU-CVE-2025-52566","published":"2025-06-24T04:15:00Z","modified":"2025-10-10T17:49:07.904662Z","upstream":["CVE-2025-52566"],"details":"llama.cpp is an inference of several LLM models in C/C++. Prior to version b5721, there is a signed vs. unsigned integer overflow in llama.cpp's tokenizer implementation (llama_vocab::tokenize) (src/llama-vocab.cpp:3036) resulting in unintended behavior in tokens copying size comparison. Allowing heap-overflowing llama.cpp inferencing engine with carefully manipulated text input during tokenization process. This issue has been patched in version b5721.","affected":[{"package":{"name":"llama.cpp","ecosystem":"Ubuntu:25.10","purl":"pkg:deb/ubuntu/llama.cpp@5882+dfsg-2?arch=source&distro=questing"},"ranges":[{"type":"ECOSYSTEM","events":[{"introduced":"0"}]}],"versions":["5318+dfsg-1","5318+dfsg-2","5713+dfsg-1","5760+dfsg-1","5760+dfsg-3","5760+dfsg-4","5882+dfsg-2"],"ecosystem_specific":{"binaries":[{"binary_name":"llama.cpp","binary_version":"5882+dfsg-2"}]},"database_specific":{"source":"https://github.com/canonical/ubuntu-security-notices/blob/main/osv/cve/2025/UBUNTU-CVE-2025-52566.json"}}],"references":[{"type":"REPORT","url":"https://ubuntu.com/security/CVE-2025-52566"},{"type":"REPORT","url":"https://www.cve.org/CVERecord?id=CVE-2025-52566"},{"type":"REPORT","url":"https://github.com/ggml-org/llama.cpp/security/advisories/GHSA-7rxv-5jhh-j6xx"},{"type":"REPORT","url":"https://github.com/ggml-org/llama.cpp/commit/dd6e6d0b6a4bbe3ebfc931d1eb14db2f2b1d70af"}],"severity":[{"type":"CVSS_V3","score":"CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H"},{"type":"CVSS_V3","score":"CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H"},{"type":"Ubuntu","score":"medium"}]}
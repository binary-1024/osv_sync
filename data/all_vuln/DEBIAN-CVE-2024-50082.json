{
  "affected": [
    {
      "database_specific": {
        "source": "https://storage.googleapis.com/debian-osv/debian-cve-osv/DEBIAN-CVE-2024-50082.json"
      },
      "ecosystem_specific": {
        "urgency": "not yet assigned"
      },
      "package": {
        "ecosystem": "Debian:11",
        "name": "linux",
        "purl": "pkg:deb/debian/linux?arch=source"
      },
      "ranges": [
        {
          "events": [
            {
              "introduced": "0"
            },
            {
              "fixed": "5.10.234-1"
            }
          ],
          "type": "ECOSYSTEM"
        }
      ],
      "versions": [
        "5.10.103-1",
        "5.10.103-1~bpo10+1",
        "5.10.106-1",
        "5.10.113-1",
        "5.10.120-1",
        "5.10.120-1~bpo10+1",
        "5.10.127-1",
        "5.10.127-2",
        "5.10.127-2~bpo10+1",
        "5.10.136-1",
        "5.10.140-1",
        "5.10.148-1",
        "5.10.149-1",
        "5.10.149-2",
        "5.10.158-1",
        "5.10.158-2",
        "5.10.162-1",
        "5.10.178-1",
        "5.10.178-2",
        "5.10.178-3",
        "5.10.179-1",
        "5.10.179-2",
        "5.10.179-3",
        "5.10.179-4",
        "5.10.179-5",
        "5.10.191-1",
        "5.10.197-1",
        "5.10.205-1",
        "5.10.205-2",
        "5.10.209-1",
        "5.10.209-2",
        "5.10.216-1",
        "5.10.218-1",
        "5.10.221-1",
        "5.10.223-1",
        "5.10.226-1",
        "5.10.46-4",
        "5.10.46-5",
        "5.10.70-1",
        "5.10.70-1~bpo10+1",
        "5.10.84-1",
        "5.10.92-1",
        "5.10.92-1~bpo10+1",
        "5.10.92-2"
      ]
    },
    {
      "database_specific": {
        "source": "https://storage.googleapis.com/debian-osv/debian-cve-osv/DEBIAN-CVE-2024-50082.json"
      },
      "ecosystem_specific": {
        "urgency": "not yet assigned"
      },
      "package": {
        "ecosystem": "Debian:12",
        "name": "linux",
        "purl": "pkg:deb/debian/linux?arch=source"
      },
      "ranges": [
        {
          "events": [
            {
              "introduced": "0"
            },
            {
              "fixed": "6.1.115-1"
            }
          ],
          "type": "ECOSYSTEM"
        }
      ],
      "versions": [
        "6.1.106-1",
        "6.1.106-2",
        "6.1.106-3",
        "6.1.112-1",
        "6.1.27-1",
        "6.1.37-1",
        "6.1.38-1",
        "6.1.38-2",
        "6.1.38-2~bpo11+1",
        "6.1.38-3",
        "6.1.38-4",
        "6.1.38-4~bpo11+1",
        "6.1.52-1",
        "6.1.55-1",
        "6.1.55-1~bpo11+1",
        "6.1.64-1",
        "6.1.66-1",
        "6.1.67-1",
        "6.1.69-1",
        "6.1.69-1~bpo11+1",
        "6.1.76-1",
        "6.1.76-1~bpo11+1",
        "6.1.82-1",
        "6.1.85-1",
        "6.1.90-1",
        "6.1.90-1~bpo11+1",
        "6.1.94-1",
        "6.1.94-1~bpo11+1",
        "6.1.98-1",
        "6.1.99-1"
      ]
    },
    {
      "database_specific": {
        "source": "https://storage.googleapis.com/debian-osv/debian-cve-osv/DEBIAN-CVE-2024-50082.json"
      },
      "ecosystem_specific": {
        "urgency": "not yet assigned"
      },
      "package": {
        "ecosystem": "Debian:13",
        "name": "linux",
        "purl": "pkg:deb/debian/linux?arch=source"
      },
      "ranges": [
        {
          "events": [
            {
              "introduced": "0"
            },
            {
              "fixed": "6.11.5-1"
            }
          ],
          "type": "ECOSYSTEM"
        }
      ],
      "versions": []
    },
    {
      "database_specific": {
        "source": "https://storage.googleapis.com/debian-osv/debian-cve-osv/DEBIAN-CVE-2024-50082.json"
      },
      "ecosystem_specific": {
        "urgency": "not yet assigned"
      },
      "package": {
        "ecosystem": "Debian:14",
        "name": "linux",
        "purl": "pkg:deb/debian/linux?arch=source"
      },
      "ranges": [
        {
          "events": [
            {
              "introduced": "0"
            },
            {
              "fixed": "6.11.5-1"
            }
          ],
          "type": "ECOSYSTEM"
        }
      ],
      "versions": []
    },
    {
      "database_specific": {
        "source": "https://storage.googleapis.com/debian-osv/debian-cve-osv/DEBIAN-CVE-2024-50082.json"
      },
      "ecosystem_specific": {
        "urgency": "not yet assigned"
      },
      "package": {
        "ecosystem": "Debian:11",
        "name": "linux-6.1",
        "purl": "pkg:deb/debian/linux-6.1?arch=source"
      },
      "ranges": [
        {
          "events": [
            {
              "introduced": "0"
            },
            {
              "fixed": "6.1.119-1~deb11u1"
            }
          ],
          "type": "ECOSYSTEM"
        }
      ],
      "versions": [
        "6.1.106-3~deb11u1",
        "6.1.106-3~deb11u2",
        "6.1.106-3~deb11u3",
        "6.1.112-1~deb11u1"
      ]
    }
  ],
  "details": "In the Linux kernel, the following vulnerability has been resolved:  blk-rq-qos: fix crash on rq_qos_wait vs. rq_qos_wake_function race  We're seeing crashes from rq_qos_wake_function that look like this:    BUG: unable to handle page fault for address: ffffafe180a40084   #PF: supervisor write access in kernel mode   #PF: error_code(0x0002) - not-present page   PGD 100000067 P4D 100000067 PUD 10027c067 PMD 10115d067 PTE 0   Oops: Oops: 0002 [#1] PREEMPT SMP PTI   CPU: 17 UID: 0 PID: 0 Comm: swapper/17 Not tainted 6.12.0-rc3-00013-geca631b8fe80 #11   Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.16.0-0-gd239552ce722-prebuilt.qemu.org 04/01/2014   RIP: 0010:_raw_spin_lock_irqsave+0x1d/0x40   Code: 90 90 90 90 90 90 90 90 90 90 90 90 90 f3 0f 1e fa 0f 1f 44 00 00 41 54 9c 41 5c fa 65 ff 05 62 97 30 4c 31 c0 ba 01 00 00 00 <f0> 0f b1 17 75 0a 4c 89 e0 41 5c c3 cc cc cc cc 89 c6 e8 2c 0b 00   RSP: 0018:ffffafe180580ca0 EFLAGS: 00010046   RAX: 0000000000000000 RBX: ffffafe180a3f7a8 RCX: 0000000000000011   RDX: 0000000000000001 RSI: 0000000000000003 RDI: ffffafe180a40084   RBP: 0000000000000000 R08: 00000000001e7240 R09: 0000000000000011   R10: 0000000000000028 R11: 0000000000000888 R12: 0000000000000002   R13: ffffafe180a40084 R14: 0000000000000000 R15: 0000000000000003   FS:  0000000000000000(0000) GS:ffff9aaf1f280000(0000) knlGS:0000000000000000   CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033   CR2: ffffafe180a40084 CR3: 000000010e428002 CR4: 0000000000770ef0   DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000   DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400   PKRU: 55555554   Call Trace:    <IRQ>    try_to_wake_up+0x5a/0x6a0    rq_qos_wake_function+0x71/0x80    __wake_up_common+0x75/0xa0    __wake_up+0x36/0x60    scale_up.part.0+0x50/0x110    wb_timer_fn+0x227/0x450    ...  So rq_qos_wake_function() calls wake_up_process(data->task), which calls try_to_wake_up(), which faults in raw_spin_lock_irqsave(&p->pi_lock).  p comes from data->task, and data comes from the waitqueue entry, which is stored on the waiter's stack in rq_qos_wait(). Analyzing the core dump with drgn, I found that the waiter had already woken up and moved on to a completely unrelated code path, clobbering what was previously data->task. Meanwhile, the waker was passing the clobbered garbage in data->task to wake_up_process(), leading to the crash.  What's happening is that in between rq_qos_wake_function() deleting the waitqueue entry and calling wake_up_process(), rq_qos_wait() is finding that it already got a token and returning. The race looks like this:  rq_qos_wait()                           rq_qos_wake_function() ============================================================== prepare_to_wait_exclusive()                                         data->got_token = true;                                         list_del_init(&curr->entry); if (data.got_token)         break; finish_wait(&rqw->wait, &data.wq);   ^- returns immediately because      list_empty_careful(&wq_entry->entry)      is true ... return, go do something else ...                                         wake_up_process(data->task)                                           (NO LONGER VALID!)-^  Normally, finish_wait() is supposed to synchronize against the waker. But, as noted above, it is returning immediately because the waitqueue entry has already been removed from the waitqueue.  The bug is that rq_qos_wake_function() is accessing the waitqueue entry AFTER deleting it. Note that autoremove_wake_function() wakes the waiter and THEN deletes the waitqueue entry, which is the proper order.  Fix it by swapping the order. We also need to use list_del_init_careful() to match the list_empty_careful() in finish_wait().",
  "id": "DEBIAN-CVE-2024-50082",
  "modified": "2025-09-25T04:16:51.502747Z",
  "published": "2024-10-29T01:15:05Z",
  "references": [
    {
      "type": "ADVISORY",
      "url": "https://security-tracker.debian.org/tracker/CVE-2024-50082"
    }
  ],
  "schema_version": "1.7.3",
  "upstream": [
    "CVE-2024-50082"
  ]
}
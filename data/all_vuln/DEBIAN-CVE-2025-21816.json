{
  "affected": [
    {
      "database_specific": {
        "source": "https://storage.googleapis.com/debian-osv/debian-cve-osv/DEBIAN-CVE-2025-21816.json"
      },
      "ecosystem_specific": {
        "urgency": "not yet assigned"
      },
      "package": {
        "ecosystem": "Debian:12",
        "name": "linux",
        "purl": "pkg:deb/debian/linux?arch=source"
      },
      "ranges": [
        {
          "events": [
            {
              "introduced": "0"
            },
            {
              "fixed": "6.1.147-1"
            }
          ],
          "type": "ECOSYSTEM"
        }
      ],
      "versions": [
        "6.1.106-1",
        "6.1.106-2",
        "6.1.106-3",
        "6.1.112-1",
        "6.1.115-1",
        "6.1.119-1",
        "6.1.123-1",
        "6.1.124-1",
        "6.1.128-1",
        "6.1.129-1",
        "6.1.133-1",
        "6.1.135-1",
        "6.1.137-1",
        "6.1.139-1",
        "6.1.140-1",
        "6.1.27-1",
        "6.1.37-1",
        "6.1.38-1",
        "6.1.38-2",
        "6.1.38-2~bpo11+1",
        "6.1.38-3",
        "6.1.38-4",
        "6.1.38-4~bpo11+1",
        "6.1.52-1",
        "6.1.55-1",
        "6.1.55-1~bpo11+1",
        "6.1.64-1",
        "6.1.66-1",
        "6.1.67-1",
        "6.1.69-1",
        "6.1.69-1~bpo11+1",
        "6.1.76-1",
        "6.1.76-1~bpo11+1",
        "6.1.82-1",
        "6.1.85-1",
        "6.1.90-1",
        "6.1.90-1~bpo11+1",
        "6.1.94-1",
        "6.1.94-1~bpo11+1",
        "6.1.98-1",
        "6.1.99-1"
      ]
    },
    {
      "database_specific": {
        "source": "https://storage.googleapis.com/debian-osv/debian-cve-osv/DEBIAN-CVE-2025-21816.json"
      },
      "ecosystem_specific": {
        "urgency": "not yet assigned"
      },
      "package": {
        "ecosystem": "Debian:13",
        "name": "linux",
        "purl": "pkg:deb/debian/linux?arch=source"
      },
      "ranges": [
        {
          "events": [
            {
              "introduced": "0"
            },
            {
              "fixed": "6.12.15-1"
            }
          ],
          "type": "ECOSYSTEM"
        }
      ],
      "versions": []
    },
    {
      "database_specific": {
        "source": "https://storage.googleapis.com/debian-osv/debian-cve-osv/DEBIAN-CVE-2025-21816.json"
      },
      "ecosystem_specific": {
        "urgency": "not yet assigned"
      },
      "package": {
        "ecosystem": "Debian:14",
        "name": "linux",
        "purl": "pkg:deb/debian/linux?arch=source"
      },
      "ranges": [
        {
          "events": [
            {
              "introduced": "0"
            },
            {
              "fixed": "6.12.15-1"
            }
          ],
          "type": "ECOSYSTEM"
        }
      ],
      "versions": []
    }
  ],
  "details": "In the Linux kernel, the following vulnerability has been resolved:  hrtimers: Force migrate away hrtimers queued after CPUHP_AP_HRTIMERS_DYING  hrtimers are migrated away from the dying CPU to any online target at the CPUHP_AP_HRTIMERS_DYING stage in order not to delay bandwidth timers handling tasks involved in the CPU hotplug forward progress.  However wakeups can still be performed by the outgoing CPU after CPUHP_AP_HRTIMERS_DYING. Those can result again in bandwidth timers being armed. Depending on several considerations (crystal ball power management based election, earliest timer already enqueued, timer migration enabled or not), the target may eventually be the current CPU even if offline. If that happens, the timer is eventually ignored.  The most notable example is RCU which had to deal with each and every of those wake-ups by deferring them to an online CPU, along with related workarounds:  _ e787644caf76 (rcu: Defer RCU kthreads wakeup when CPU is dying) _ 9139f93209d1 (rcu/nocb: Fix RT throttling hrtimer armed from offline CPU) _ f7345ccc62a4 (rcu/nocb: Fix rcuog wake-up from offline softirq)  The problem isn't confined to RCU though as the stop machine kthread (which runs CPUHP_AP_HRTIMERS_DYING) reports its completion at the end of its work through cpu_stop_signal_done() and performs a wake up that eventually arms the deadline server timer:     WARNING: CPU: 94 PID: 588 at kernel/time/hrtimer.c:1086 hrtimer_start_range_ns+0x289/0x2d0    CPU: 94 UID: 0 PID: 588 Comm: migration/94 Not tainted    Stopper: multi_cpu_stop+0x0/0x120 <- stop_machine_cpuslocked+0x66/0xc0    RIP: 0010:hrtimer_start_range_ns+0x289/0x2d0    Call Trace:    <TASK>      start_dl_timer      enqueue_dl_entity      dl_server_start      enqueue_task_fair      enqueue_task      ttwu_do_activate      try_to_wake_up      complete      cpu_stopper_thread  Instead of providing yet another bandaid to work around the situation, fix it in the hrtimers infrastructure instead: always migrate away a timer to an online target whenever it is enqueued from an offline CPU.  This will also allow to revert all the above RCU disgraceful hacks.",
  "id": "DEBIAN-CVE-2025-21816",
  "modified": "2025-09-24T00:56:26.042103Z",
  "published": "2025-02-27T20:16:04Z",
  "references": [
    {
      "type": "ADVISORY",
      "url": "https://security-tracker.debian.org/tracker/CVE-2025-21816"
    }
  ],
  "schema_version": "1.7.3"
}